\chapter{Concepts and algorithms}
\hypertarget{concepts_and_algorithms}{}\label{concepts_and_algorithms}\index{Concepts and algorithms@{Concepts and algorithms}}
\hypertarget{concepts_and_algorithms_kMC_sim_overview}{}\doxysection{\texorpdfstring{Basics of kinetic Monte Carlo simulation as implemented in the ARL KMCThin\+Film library}{Basics of kinetic Monte Carlo simulation as implemented in the ARL KMCThin\+Film library}}\label{concepts_and_algorithms_kMC_sim_overview}
In the ARL \doxylink{namespaceKMCThinFilm}{KMCThin\+Film} library, a simulation is an object that executes the {\itshape n}-\/fold way algorithm \cite{bor75}, where at a given time step in the simulation, the set of all possible events in a system and their associated rate constants or propensities (i.\+e. probabilities per unit time) is determined, and one of these events is then randomly chosen to be executed, with the choice weighted according the propensities of the possible events. Following a later k\+MC work \cite{fic91}, the simulation time at each step is advanced by $-\ln{r}/p_{tot}$, where {\itshape r} is a random number uniformly chosen from the open interval (0,1), and $p_{tot}$ is the sum of all the propensities of all possible events. To simplify the process of determining the set of possible events, each possible event is assumed to cause some sort of change to cells in a lattice. This lattice is itself an object that is owned by the simulation object, and it is initialized when the simulation object is initialized. Possible events are assumed to be of one of two kinds\+:


\begin{DoxyItemize}
\item {\itshape Cell-\/centered}. This is a type of event that originates in the neighborhood of some lattice cell, and a propensity of an instance of such an event at a particular cell is affected by the states of cells in the neighborhood of that particular cell. Adsorption, diffusion, or chemical reactions are examples of such events. Since the propensities of related cell-\/centered events can often be calculated using the same or almost the same series of steps, types of cell-\/centered events may be collected into one or more groups. A group of cell-\/centered event types consists of the following components\+:
\begin{DoxyItemize}
\item An integer label identifying the group of event types.
\item A set of the relative locations of the cells in the aforementioned neighborhood, which are called ``\doxylink{classKMCThinFilm_1_1CellIndsOffset}{offsets}.''
\item A function or function object that calculates what amounts to an array (or more precisely, an \href{http://www.cplusplus.com/reference/vector/}{\texttt{ STL vector}}) of propensities, one for each instance of a type of event in the group happening at a given cell. This function/function object is given very limited access to the lattice object owned by the simulation. In particular, it can only read the states of lattice cells within the neighborhood of cells defined by the offsets mentioned above.
\item A group of functions or function objects, one for each type of event in the group of cell-\/centered event types, that can execute an instance of that event type about a given cell. Each of these function/function objects can alter the lattice that is owned by the simulation object, and not just the cells of the lattice within a certain neighborhood of the cell about which an event is centered. In addition, it has read-\/only access to some aspects of the current \doxylink{classKMCThinFilm_1_1SimulationState}{simulation state}, such as the elapsed simulation time. Optionally, for each function/function object in the group, there may be a set of offsets that indicate the relative locations of cells directly changed by the execution of the event, and this may be used to speed up the simulation.
\end{DoxyItemize}
\item {\itshape Over-\/lattice}. This is a type of event that, from a physical perspective, is assumed to have actually originated at some point well above the lattice, out of the range of influence of things that happen at the surface or interior of the lattice. Deposition would be the chief example of this type of event. An over-\/lattice event type consists of the following components\+:
\begin{DoxyItemize}
\item An integer label identifying the type of event.
\item A propensity per unit area, i.\+e., the propensity of the event divided by the number of cells in a lattice monolayer. A deposition flux given in terms of the number of monolayers per unit time is already a propensity per unit area.
\item A function or function object that can execute an instance of this event type originating from a randomly picked cell at the top of the lattice. This function/function object can alter the lattice that is owned by the simulation object, and if need be, it can alter cells that are far distant from the originating randomly picked cell. It also has read-\/only access to some aspects of the current \doxylink{classKMCThinFilm_1_1SimulationState}{simulation state}, (e.\+g. elapsed simulation time).
\end{DoxyItemize}
\end{DoxyItemize}

After the simulation object is initialized, these event types are added to the object. Once these types are added, the simulation is then run for a certain amount of simulation time. A simulation can also be restarted from where it left off, and before restarting, event types can be added, modified, or removed from a simulation object. For example, one could add both deposition and diffusion event types to a simulation, run the simulation for $t_{dep}$ units of time, then remove the deposition event type, change the objects that calculate the propensities of the diffusion event type to those for a higher temperature, and then restart the simulation from where it left off for $t_{anneal}$ units of simulation time.

At the beginning of a simulation run, each cell of the lattice is scanned in order to determine the initial set of possible events and their propensities. When an event is executed at a time step, the locations of the lattice cells directly changed by this event, as well as certain cells within a neighborhood of these changed cells, are recorded. The list of recorded cell indices, then, is used to incrementally update the set of possible events and propensities, avoiding the computational cost of scanning each cell of the the lattice at each time step to refresh this set. This list is constructed from the offsets used to define cell-\/centered events. More precisely, it is constructed using a master list of offsets that is generated at the beginning of the simulation run, one that is the union of all the offsets of cell-\/centered events. If {\itshape auto-\/tracking} is used to track the locations of the directly affected cells, then when an event is executed, for each cell $(a_n,b_n,c_n)$ directly changed by the event, cell indices $(a_n,b_n,c_n)$,  $(a_n - i_1, b_n -
j_1, c_n - k_1)$, $(a_n - i_2, b_n - j_2, c_n - k_2)$, etc. will be added to the list of indices of cells affected by the event, where $(i_1,j_1,k_1)$, $(i_2,j_2,k_2)$, {$\dots$}, is the master list of offsets. When this list of indices is constructed in this way, there may be redundancies in the list. These redundancies won\textquotesingle{}t lead to spurious results, but they will lead to redundant propensity calculations, since a propensity calculation is done for every item in the list. To avoid this, {\itshape semi-\/manual} tracking may be used. To use this mode of tracking for a cell-\/centered event, sets of offsets  $\{O_1, O_2,
\dots\}$, indicating the relative locations of cells changed by an event, must be specified for the type of this cell-\/centered event. From this information and the master list of offsets, new lists of offsets are constructed, one for each set $O_m$. For each offset $(a^m_n,b^m_n,c^m_n)$ in set $O_m$, a list of offsets  $l^m_n = (a^m_n,b^m_n,c^m_n), (a^m_n - i_1, b^m_n - j_1,
c^m_n - k_1), (a^m_n - i_2, b^m_n - j_2, c^m_n - k_2)$, etc. is generated, where $(i_1,j_1,k_1)$, $(i_2,j_2,k_2)$, {$\dots$}, again is the master list of offsets. The list $L_m$ is then constructed as the union of all offsets in the lists $l^m_1$, $l^m_2$, {$\dots$}. When an event is executed, for each set $O_m$, one of the cells affected by the event is designated as {\itshape center} $m$. For each center $m$, the indices of the rest of the cells changed by the event are formed adding the indices of this center to each of the offsets in $O_m$. The list of recorded cell indices is then composed of the indices of these centers, and the indices formed from adding the indices of center $m$ to each of the offsets in $L_m$. If the centers are far enough apart or there is only one center, then the list of recorded cell indices should have no redundant values.

The process of choosing a random event may be done with one of two algorithms, which in the ARL \doxylink{namespaceKMCThinFilm}{KMCThin\+Film} library are called {\itshape solvers}. One algorithm \cite{blu95} stores the {\itshape N} possible events and partial sums of their propensities in a binary tree and scales as  $O(\log_2
N)$. Another algorithm stores possible events in a map where the key is a propensity of a possible event, and the value associated with that key is an array of possible events associated with that propensity. This algorithm scales with the number of unique propensity values in the system, which in many cases is independent of the number of possible events {\itshape N}. This is similar to another algorithm \cite{sch02}, except that algorithm used a two-\/dimensional array rather than a map.

In addition to possible events, {\itshape periodic actions} can be executed during a simulation as well. There are two types of periodic actions\+: {\itshape time-\/periodic} actions, which occur after every {\itshape t} units of simulation time, and {\itshape step-\/periodic} actions, which occur after every {\itshape M} time steps. These may perform various functions, from I/O operations, e.\+g. to record to a file the state of the lattice at various points during a simulation, or to even change the lattice or quantities associated with it. Like possible events, periodic actions can be added, changed, or removed from a simulation object.\hypertarget{concepts_and_algorithms_lattice_overview}{}\doxysection{\texorpdfstring{Lattices in the ARL KMCThin\+Film library}{Lattices in the ARL KMCThin\+Film library}}\label{concepts_and_algorithms_lattice_overview}
A lattice in the ARL \doxylink{namespaceKMCThinFilm}{KMCThin\+Film} library is modeled as a stack of two-\/dimensional arrays of cells, with each cell labeled with a triplet of integer indices, as illustrated in the figure below.

 
\begin{DoxyImageNoCaption}
  \mbox{\includegraphics[width=0.8\textwidth]{LatticeModel}}
\end{DoxyImageNoCaption}


Periodic boundary conditions always apply to the first two indices of a cell, but not the third. In a manner similar to that of the software SPPARKS \texorpdfstring{$<$}{<}\href{http://spparks.sandia.gov}{\texttt{ http\+://spparks.\+sandia.\+gov}}\texorpdfstring{$>$}{>}, each cell also contains two one-\/dimensional arrays, one with integer values and one with double precision floating-\/point values. The size of these arrays is the same for all cells. The physical meaning of the contents of the arrays is left up to the client application that uses the ARL \doxylink{namespaceKMCThinFilm}{KMCThin\+Film} library; for a given application, they may be used to identify species of a basis of atoms within a cell, or the spatial coordinates of an atom in a cell in a possibly distorted lattice, or, for a simpler solid-\/on-\/solid application, the height of a column of atoms at $(i,j,0)$. The lattice need not be cubic. If the cells are treated as those of a Bravais lattice with primitive lattice vectors $\mathbf{a}_i$, $\mathbf{a}_j$, and $\mathbf{a}_k$, then the physical location of cell $(i,j,k)$ may be said to be  $\mathbf{a}_i i + \mathbf{a}_j j
+ \mathbf{a}_k k$. The sizes of the arrays in each cell of the lattice, as well as the maximum values of the first two indices of a cell, are fixed when the lattice is initialized, but additional planes may be added to the lattice at any time step of the simulation.\hypertarget{concepts_and_algorithms_kmc_par_alg}{}\doxysection{\texorpdfstring{Parallel approximate Kinetic Monte Carlo algorithm}{Parallel approximate Kinetic Monte Carlo algorithm}}\label{concepts_and_algorithms_kmc_par_alg}
The lattice in a parallel k\+MC simulation is partitioned among the processors in an MPI communicator. There are two methods of decomposition. The simplest is row-\/based decomposition, shown below.

 
\begin{DoxyImageNoCaption}
  \mbox{\includegraphics[width=0.7\textwidth]{PartitionedLatticeRow}}
\end{DoxyImageNoCaption}


In the above diagram, a lattice is divided among four processors with ranks ranging from 0 to 3. Here, ``ghost sites'' appear along the top and bottom of each partition of the lattice. The ghost regions along the edges of each partition are copies of the lattice sites of a neighboring processor, and in the diagram, the processor from which they are copied is shown via their color. Periodic boundary conditions are employed here, so that the top of the rank 0 partition is connected to the bottom of the rank 3 partition. Ghost regions are not needed for the left and right sides. Alternatively, the lattice may be decomposed such that the perimeter of each partition is minimized. Here, this is called {\itshape compact} decomposition, and is shown below.

 
\begin{DoxyImageNoCaption}
  \mbox{\includegraphics[width=0.8\textwidth]{PartitionedLatticeCompact}}
\end{DoxyImageNoCaption}


Now, ghost regions are along the whole boundary of each portion of the lattice. Again, the lattice is shown divided among four processors with ranks ranging from 0 to 3.

Attempting to do k\+MC simulations on each partition of the lattice would lead to problems at the partition boundaries, since the events done on each partition could lead to conflicting effects on the ghost sites. To avoid this problem, an approximate k\+MC algorithm was developed \cite{shim05}, where each partition is further subdivided into sectors, and at any given time in the simulation, events are executed only for sites within one of these sectors, as illustrated below for the case of compact decomposition.

 
\begin{DoxyImageNoCaption}
  \mbox{\includegraphics[width=0.5\textwidth]{ActiveSectorsCompact}}
\end{DoxyImageNoCaption}


Partition boundaries are indicated by thick solid lines, while the sector boundaries are indicated by thinner solid lines. Active sectors are shown in the color corresponding to the rank of the partition to which they belong. The dotted lines show the boundaries of the regions affected by events that occur within the active sectors. The parts of these regions that affect ghost sites are shown in the color corresponding to the ranks of the sites of which the ghost sites are copies. If row decomposition were used, there would be two sectors per partition instead of four. Here, in the above diagram, the active sectors happen to be the upper left quadrants of the lattice partitions. At any given time in the simulation, they could be the lower left, lower right, or upper right quadrants, so long as the relative locations of these active sectors are the same for all processors, that is, {\itshape all} upper left, {\itshape all} lower left, and so on. Because the active sectors all have the same relative location, the regions that are affected by events happening within them do not overlap, as illustrated by the diagram above.

With the sectors now defined, the approximate k\+MC algorithm can proceed on each processor as follows\+:


\begin{DoxyEnumerate}
\item Initialize the global time {\itshape t} to zero.
\item Determine the initial value of the stop time $t_{stop}$.
\item Repeat the following until {\itshape t} exceed the desired time $t_{max}$\+:
\begin{DoxyEnumerate}
\item Iterate over the sectors. For each sector visited,
\begin{DoxyEnumerate}
\item initialize the local time $t_{local}$ to zero,
\item update the ghost sites and the set of possible events affected by changes to the ghost sites,
\item run a normal serial k\+MC algorithm on the sites within the sector, incrementing $t_{local}$ as each event is executed until $t_{local} > t_{stop}$, but do not allow the event that would cause $t_{local}$ to exceed $t_{stop}$ to be executed, and
\item update the off-\/processor sites that correspond to the ghost sites that have changed due to the events that have occurred, and again update the set of possible events affected by the ghost site updates.
\end{DoxyEnumerate}
\item Increment the global time {\itshape t} by $t_{stop}$.
\item Update the value of $t_{stop}$.
\end{DoxyEnumerate}
\end{DoxyEnumerate}

The updates of the ghost sites that are performed when a sector is visited do not involve communicating the entirety of the ghost site regions bordering a sector, only the communication of {\itshape changes} to each region.

In principle, the sequence in which the sectors are visited may be random, so long as (1) each processor uses the same random sequences (in order that the active sectors on each processor are at the same relative location, as mentioned previously), and (2) that four sectors are visited before the global time is incremented. However, in the ARL \doxylink{namespaceKMCThinFilm}{KMCThin\+Film} library, the simpler approach seen in another k\+MC code, SPPARKS \cite{plim23}, is taken, where each sector is simply visited in turn in a deterministic loop. In the ARL \doxylink{namespaceKMCThinFilm}{KMCThin\+Film} library, this loop begins at the upper left and then continues to the lower left, followed by the lower right and upper right.

Compact decomposition, despite minimizing the perimeter of each partition, may be slower than row-\/based decomposition, because the former mode of decomposition requires twice as many sectors as the latter, and each visit of a sector requires the communication of ghosts. The volume of data communicated in row-\/based decomposition may indeed be higher than that in compact decomposition. However, since only changes to ghost regions are communicated, this volume is not that high to begin with, so the communication overhead is dominated more by the very acts of sending and receiving messages, rather the costs associated with the size of the data itself. Because of this, row-\/based decomposition is the default in the ARL \doxylink{namespaceKMCThinFilm}{KMCThin\+Film} library.

The value of $t_{stop}$ may be determined by various time-\/stepping schemes. The simplest of these is to set $t_{stop}$ to a fixed value. The other schemes are various kinds of adaptive algorithms, which attempt to determine a reasonable value of $t_{stop}$ from the propensities of the possible events in the simulation. In all of these algorithms, the time step has the general form,   \[t_{stop} = \frac{n_{stop}}{F_{stop}}
\] where $n_{stop}$ is an adjustable parameter, and $F_{stop}$ is a function that determines the particular adaptive time step scheme. Here are the currently available choices for $F_{stop}$\+:


\begin{DoxyItemize}
\item The maximum propensity of all currently possible cell-\/centered events in the simulation. This is a simplified version of the adaptive method of determining $F_{stop}$ recommended by \cite{shim05}. When this method is used, a good conservative value of $n_{stop}$ is 1.\+0, though in some applications, such as island coarsening, a value of up to 10.\+0 has been used without much loss of accuracy \cite{shi07}.
\item The maximum of the average propensities per possible cell-\/centered event from each sector.  $F_{stop} = \max(p_s^1,
  p_s^2, \dots, p_s^{N_{proc}})$, where $N_{proc}$ is the number of processors and for the case of compact decomposition, $p_s^n = \max(p_{s,UL}^n,p_{s,LL}^n,p_{s,LR}^n,p_{s,UR}^n)$, where $p_{s,UL}^n$ is the average propensity of the events in the upper-\/left sector of partition {\itshape n}, that is, the sum of the propensities of all possible events in that sector divided by the number of possible events, and similarly, $p_{s,LL}^n$, $p_{s,LR}^n$, and $p_{s,UR}^n$ are the mean propensities in the lower left, lower right, and upper right sectors of partition {\itshape n}, as in SPPARKS \cite{plim23}. For this choice of $F_{stop}$, a reasonable starting value for $n_{stop}$ is 1.\+0. Note that for a given value of $n_{stop}$, this approach may be less conservative than the previous one.
\end{DoxyItemize}

An additional optional parameter $t_{stop,max}$ may be used with the adaptive schemes. If this parameter is set, then if $n_{stop}/F_{stop} > t_{stop,max}$, $t_{stop}$ will equal $t_{stop,max}$ instead of $n_{stop}/F_{stop}$. This may be useful in cases where the adaptive scheme temporarily overestimates $t_{stop}$ during a simulation.

In a parallel simulation, the propensity of an over-\/lattice event is the propensity per unit area scaled by the in-\/plane area of a {\itshape sector}, rather than the size of a whole monolayer. Also, running a parallel simulation changes how periodic actions are run. In a serial simulation, if a periodic action executes, it executes shortly after an event has been executed. In a parallel simulation, if a periodic action executes, it executes shortly after $t_{stop}$ has been incremented, that is, outside of the looping over sectors. This allows periodic actions to use MPI calls for parallel communication, since a periodic action will execute the same number of times on every processor. 